{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6KCVqhrjegCeAP65dpnrC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_-TyYLQ1EBw","executionInfo":{"status":"ok","timestamp":1747683359622,"user_tz":-180,"elapsed":2249,"user":{"displayName":"maven","userId":"12646367618341248502"}},"outputId":"7a1f888d-1b1b-4b56-82c8-7429f2ab4ac3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\"\"\" Klasör oluşturma fonksiyonu \"\"\"\n","def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)"],"metadata":{"id":"VL0_j4I18MKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BjbPxmx0_rJ","executionInfo":{"status":"ok","timestamp":1747694875355,"user_tz":-180,"elapsed":8170394,"user":{"displayName":"maven","userId":"12646367618341248502"}},"outputId":"97a913e2-ecee-484d-fe69-bfca4f40a567"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.2391 - loss: 0.1818 \n","Epoch 1: val_loss improved from inf to 0.36743, saving model to /content/drive/MyDrive/model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2360s\u001b[0m 18s/step - accuracy: 0.2395 - loss: 0.1812 - val_accuracy: 0.0112 - val_loss: 0.3674 - learning_rate: 1.0000e-04\n","Epoch 2/5\n","\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.4148 - loss: 0.0461 \n","Epoch 2: val_loss improved from 0.36743 to 0.27520, saving model to /content/drive/MyDrive/model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2259s\u001b[0m 18s/step - accuracy: 0.4146 - loss: 0.0461 - val_accuracy: 0.2640 - val_loss: 0.2752 - learning_rate: 1.0000e-04\n","Epoch 3/5\n","\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.3590 - loss: 0.0374 \n","Epoch 3: val_loss improved from 0.27520 to 0.18097, saving model to /content/drive/MyDrive/model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2293s\u001b[0m 18s/step - accuracy: 0.3591 - loss: 0.0375 - val_accuracy: 0.4167 - val_loss: 0.1810 - learning_rate: 1.0000e-04\n","Epoch 4/5\n","\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.3680 - loss: 0.0323 \n","Epoch 4: val_loss improved from 0.18097 to 0.08815, saving model to /content/drive/MyDrive/model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2223s\u001b[0m 18s/step - accuracy: 0.3682 - loss: 0.0323 - val_accuracy: 0.2679 - val_loss: 0.0882 - learning_rate: 1.0000e-04\n","Epoch 5/5\n","\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.4360 - loss: 0.0383 \n","Epoch 5: val_loss improved from 0.08815 to 0.04173, saving model to /content/drive/MyDrive/model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2327s\u001b[0m 19s/step - accuracy: 0.4360 - loss: 0.0383 - val_accuracy: 0.2951 - val_loss: 0.0417 - learning_rate: 1.0000e-04\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a026a782310>"]},"metadata":{},"execution_count":15}],"source":["import random\n","import os\n","import glob\n","import tensorflow as tf\n","import sys\n","sys.path.append('/content/drive/MyDrive')\n","from unet import build_unet\n","\n","# -----------------------------\n","# Parametreler\n","# -----------------------------\n","NUM_CLASSES = 4\n","BATCH_SIZE = 8\n","INPUT_SHAPE = (128, 128, 3)\n","NUM_EPOCHS = 5\n","SAMPLE_SIZE = 1000  # Sadece 100 görüntü rastgele alınacak\n","\n","# -----------------------------\n","# Verileri Al\n","# -----------------------------\n","image_path = \"/content/drive/MyDrive/patches_unzipped/patches/images\"\n","mask_path = \"/content/drive/MyDrive/patches_unzipped/patches/masks\"\n","\n","image_paths = sorted(glob.glob(os.path.join(image_path, \"*.png\")))\n","mask_paths = sorted(glob.glob(os.path.join(mask_path, \"*.png\")))\n","\n","# Rastgele 100 örnek seç\n","combined = list(zip(image_paths, mask_paths))\n","random.shuffle(combined)\n","sampled = combined[:SAMPLE_SIZE]\n","image_paths, mask_paths = zip(*sampled)\n","\n","# -----------------------------\n","# Ön işlem fonksiyonu\n","# -----------------------------\n","def preprocess(image_path, mask_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_png(image, channels=3)\n","    image = tf.image.resize(image, INPUT_SHAPE[:2])\n","    image = tf.cast(image, tf.float32) / 255.0\n","\n","    mask = tf.io.read_file(mask_path)\n","    mask = tf.image.decode_png(mask, channels=1)\n","    mask = tf.image.resize(mask, INPUT_SHAPE[:2], method='nearest')\n","    mask = tf.one_hot(tf.squeeze(mask, axis=-1), NUM_CLASSES)\n","\n","    return image, mask\n","\n","# -----------------------------\n","# Dataset oluştur\n","# -----------------------------\n","def create_dataset(image_paths, mask_paths, batch_size):\n","    dataset = tf.data.Dataset.from_tensor_slices((list(image_paths), list(mask_paths)))\n","    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n","    dataset = dataset.shuffle(100)\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","    return dataset\n","\n","train_dataset = create_dataset(image_paths, mask_paths, BATCH_SIZE)\n","valid_dataset = train_dataset.take(100)  # küçük bir doğrulama seti\n","\n","# -----------------------------\n","# Model eğitimi\n","# -----------------------------\n","model = build_unet(INPUT_SHAPE, NUM_CLASSES)\n","model.compile(\n","    loss=\"categorical_crossentropy\",\n","    optimizer=tf.keras.optimizers.Adam(1e-4),\n","    metrics=[\"accuracy\"]\n",")\n","\n","model_path = \"/content/drive/MyDrive/model.h5\"  # veya istediğin bir isim ve konum\n","csv_path = \"/content/drive/MyDrive/log.csv\"     # CSV log dosyası için yol\n","\n","\n","callbacks = [\n","    tf.keras.callbacks.ModelCheckpoint(model_path, save_best_only=True, verbose=1),\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1),\n","    tf.keras.callbacks.CSVLogger(csv_path, append=True),\n","    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","]\n","\n","model.fit(\n","    train_dataset,\n","    validation_data=valid_dataset,\n","    epochs=NUM_EPOCHS,\n","    callbacks=callbacks\n",")\n"]}]}